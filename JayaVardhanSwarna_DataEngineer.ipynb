{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "724d60f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SteelEye Data Engineer Assignment\n"
     ]
    }
   ],
   "source": [
    "print(\"SteelEye Data Engineer Assignment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8efcbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Jaya Vardhan Swarna', 'Registration Number': 12002055, 'University': 'Lovely Professional University'}\n"
     ]
    }
   ], 
   "source": [
    "My_Details = {\n",
    "  \"Name\"                : \"Jaya Vardhan Swarna\",\n",
    "  \"Registration Number\" : 12002055,\n",
    "  \"University\"          : \"Lovely Professional University\"\n",
    "}\n",
    "print(My_Details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f3688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "556e09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60264faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda:\n",
    "    '''\n",
    "    The Lambda Object has the following parameters:\n",
    "    :param url: The url to parse through the xml and extract the first download link whose file_type is DLTINS\n",
    "    Has three methods:\n",
    "    :method download_link: Requests the url to get the xml file -> Parses the Xml file to return the download_link.\n",
    "    :method zip_extraction: Downloads the zip file -> Extracts the xml file in zip file\n",
    "    :method xml_to_csv: Parse the xml file and Converts it into csv\n",
    "    '''\n",
    "    def __init__(self, url = None) -> None:\n",
    "        self.url = url\n",
    "        self.logger = logging.getLogger('lambda_function') # create logger object\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "    def download_link(self):\n",
    "        '''\n",
    "        Uses the url of the class to get the required path.\n",
    "        Creates a file 'registers.xml' in binary mode and write the path data to the xml file\n",
    "        Parse the xml file and find the required node and return the download link\n",
    "        '''\n",
    "        try:\n",
    "            self.resp = requests.get(self.url)\n",
    "            with open('registers.xml', 'wb') as f:\n",
    "                f.write(self.resp.content)\n",
    "            self.tree = ET.parse('registers.xml')\n",
    "            self.root = self.tree.getroot()\n",
    "            self.link = ''\n",
    "            for item in self.root[1].iter(\"doc\"):\n",
    "                if item.find(\"str[@name = 'file_type']\").text == 'DLTINS':\n",
    "                    self.link = item.find(\"str[@name='download_link']\").text\n",
    "                    break\n",
    "            if not self.link:\n",
    "                raise Exception('Could not find download link for file_type DLTINS')\n",
    "            return self.link\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in download_link: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def zip_extraction(self, link = None):\n",
    "        '''\n",
    "        :param link: url link to download the zip file\n",
    "        Uses the link to request the link\n",
    "        Create a file 'zip_file.zip' and write the content into the file\n",
    "        Extract the zip file and save the name of the file from the namelist and return it\n",
    "        '''\n",
    "        try:\n",
    "            self.zip_file = requests.get(self.link)\n",
    "            with open('zip_file.zip', 'wb') as f:\n",
    "                f.write(self.zip_file.content)\n",
    "            self.xml_file = ''\n",
    "            with zipfile.ZipFile('zip_file.zip', 'r') as f:\n",
    "                self.xml_file = f.namelist()[0]\n",
    "                f.extractall('')\n",
    "            if not self.xml_file:\n",
    "                raise Exception('Could not extract xml file from zip')\n",
    "            return self.xml_file\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in zip_extraction: {e}\")\n",
    "            raise e\n",
    "    \n",
    "            \n",
    "    def xml_to_csv(self, xml = None):\n",
    "        self.new = ET.parse(xml)     #parse xml\n",
    "        self.test = self.new.getroot()\n",
    "\n",
    "        self.pattern = 'FinInstrmGnlAttrbts'                                            #required node\n",
    "        self.children = ['Id', 'FullNm', 'ClssfctnTp', 'CmmdtyDerivInd', 'NtnlCcy']     #required children nodes\n",
    "        \n",
    "        self.tag = 'Issr' #required node\n",
    "\n",
    "        self.rows  = []\n",
    "        self.cols = [self.pattern + '.' + k for k in self.children]\n",
    "        self.cols.append(self.tag)\n",
    "        \n",
    "        self.parent = 'TermntdRcrd'                                    #parent node\n",
    "        \n",
    "        for i in self.test.iter():         \n",
    "            if self.parent in i.tag:                                   # If parent is found\n",
    "                self.entry = [None for x in range(len(self.cols))]     # Initialise array of required elements\n",
    "                for child in i:\n",
    "                    if self.pattern in child.tag:                      # If required child has been found\n",
    "                            for c in child:                            # Get the required grand-children\n",
    "                                for k in range(len(self.children)):\n",
    "                                        if self.children[k] in c.tag:  # If grandchildren found, update entry\n",
    "                                            self.entry[k] = c.text\n",
    "                    if self.tag in child.tag:                          # If Issr found\n",
    "                        self.entry[5] = child.text\n",
    "                self.rows.append(self.entry)                           # Add to list of rows\n",
    "                     \n",
    "        self.df = pd.DataFrame(self.rows, columns=self.cols)      \n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da8c49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    url = \"https://registers.esma.europa.eu/solr/esma_registers_firds_files/select?q=*&fq=publication_date:%5B2021-01-17T00:00:00Z+TO+2021-01-19T23:59:59Z%5D&wt=xml&indent=true&start=0&rows=100\" #Requirement-1: save the download link to url and download the xml file\n",
    "    p = Lambda(url) #create an object for class lambda \n",
    "    \n",
    "    #Requirement 2: From the xml, please parse through to the first download link whose file_type is DLTINS and download the zip\n",
    "    zip_link = p.download_link()\n",
    "    \n",
    "    #Requirement 3: Extract the xml from the zip.\n",
    "    xml_file = p.zip_extraction(zip_link)\n",
    "    \n",
    "    #Requirement 4: Convert the contents of the xml into a CSV\n",
    "    df = p.xml_to_csv(xml_file)\n",
    "    df.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "004e69e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FinInstrmGnlAttrbts.Id</th>\n",
       "      <th>FinInstrmGnlAttrbts.FullNm</th>\n",
       "      <th>FinInstrmGnlAttrbts.ClssfctnTp</th>\n",
       "      <th>FinInstrmGnlAttrbts.CmmdtyDerivInd</th>\n",
       "      <th>FinInstrmGnlAttrbts.NtnlCcy</th>\n",
       "      <th>Issr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE000A1R07V3</td>\n",
       "      <td>Kreditanst.f.Wiederaufbau     Anl.v.2014 (2021)</td>\n",
       "      <td>DBFTFB</td>\n",
       "      <td>false</td>\n",
       "      <td>EUR</td>\n",
       "      <td>549300GDPG70E3MBBU98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE000A1R07V3</td>\n",
       "      <td>KFW 1 5/8 01/15/21</td>\n",
       "      <td>DBFTFB</td>\n",
       "      <td>false</td>\n",
       "      <td>EUR</td>\n",
       "      <td>549300GDPG70E3MBBU98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE000A1R07V3</td>\n",
       "      <td>Kreditanst.f.Wiederaufbau Anl.v.2014 (2021)</td>\n",
       "      <td>DBFTFB</td>\n",
       "      <td>false</td>\n",
       "      <td>EUR</td>\n",
       "      <td>549300GDPG70E3MBBU98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE000A1R07V3</td>\n",
       "      <td>Kreditanst.f.Wiederaufbau Anl.v.2014 (2021)</td>\n",
       "      <td>DBFTFB</td>\n",
       "      <td>false</td>\n",
       "      <td>EUR</td>\n",
       "      <td>549300GDPG70E3MBBU98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE000A1X3J56</td>\n",
       "      <td>IKB Deutsche Industriebank AG Stufenz.MTN-IHS ...</td>\n",
       "      <td>DTVUFB</td>\n",
       "      <td>false</td>\n",
       "      <td>EUR</td>\n",
       "      <td>PWEFG14QWWESISQ84C69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FinInstrmGnlAttrbts.Id                         FinInstrmGnlAttrbts.FullNm  \\\n",
       "0           DE000A1R07V3    Kreditanst.f.Wiederaufbau     Anl.v.2014 (2021)   \n",
       "1           DE000A1R07V3                                 KFW 1 5/8 01/15/21   \n",
       "2           DE000A1R07V3        Kreditanst.f.Wiederaufbau Anl.v.2014 (2021)   \n",
       "3           DE000A1R07V3        Kreditanst.f.Wiederaufbau Anl.v.2014 (2021)   \n",
       "4           DE000A1X3J56  IKB Deutsche Industriebank AG Stufenz.MTN-IHS ...   \n",
       "\n",
       "  FinInstrmGnlAttrbts.ClssfctnTp FinInstrmGnlAttrbts.CmmdtyDerivInd  \\\n",
       "0                         DBFTFB                              false   \n",
       "1                         DBFTFB                              false   \n",
       "2                         DBFTFB                              false   \n",
       "3                         DBFTFB                              false   \n",
       "4                         DTVUFB                              false   \n",
       "\n",
       "  FinInstrmGnlAttrbts.NtnlCcy                  Issr  \n",
       "0                         EUR  549300GDPG70E3MBBU98  \n",
       "1                         EUR  549300GDPG70E3MBBU98  \n",
       "2                         EUR  549300GDPG70E3MBBU98  \n",
       "3                         EUR  549300GDPG70E3MBBU98  \n",
       "4                         EUR  PWEFG14QWWESISQ84C69  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ac3e521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'Y1DZDBGM8MNDF8CD',\n",
       "  'HostId': 'AYuozKgqLMlwQDRQ1Fda1Ndz4i1XGKKXKaYVh/HIuHol7HgTgtDCBNbnvKialjr08Wj4vZc/mkjFI/vJQStvBA==',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'AYuozKgqLMlwQDRQ1Fda1Ndz4i1XGKKXKaYVh/HIuHol7HgTgtDCBNbnvKialjr08Wj4vZc/mkjFI/vJQStvBA==',\n",
       "   'x-amz-request-id': 'Y1DZDBGM8MNDF8CD',\n",
       "   'date': 'Sun, 23 Apr 2023 09:35:22 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"0b4c343ed3a2c4e6cafe39d57459c5f9\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 1},\n",
       " 'ETag': '\"0b4c343ed3a2c4e6cafe39d57459c5f9\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the csv from step 4) in an AWS S3 bucket\n",
    "s3 = boto3.client(\"s3\", aws_access_key_id = \"AKIAX4EIEWN2MKO3L2K6\", aws_secret_access_key=\"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\")\n",
    "csv_buf = StringIO()\n",
    "df.to_csv(csv_buf, header = True, index = False)\n",
    "csv_buf.seek(0)\n",
    "s3.put_object(Bucket=\"steeleyedata\", Body=csv_buf.getvalue(), Key='output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d57e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6ab75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import logging\n",
    "\n",
    "class Lambda:\n",
    "    def __init__(self, url = None) -> None:\n",
    "        self.url = url\n",
    "        self.logger = logging.getLogger('lambda_function')\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "    def download_link(self):\n",
    "        try:\n",
    "            self.resp = requests.get(self.url)\n",
    "            with open('registers.xml', 'wb') as f:\n",
    "                f.write(self.resp.content)\n",
    "            self.tree = ET.parse('registers.xml')\n",
    "            self.root = self.tree.getroot()\n",
    "            self.link = ''\n",
    "            for item in self.root[1].iter(\"doc\"):\n",
    "                if item.find(\"str[@name = 'file_type']\").text == 'DLTINS':\n",
    "                    self.link = item.find(\"str[@name='download_link']\").text\n",
    "                    break\n",
    "            if not self.link:\n",
    "                raise Exception('Could not find download link for file_type DLTINS')\n",
    "            return self.link\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in download_link: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def zip_extraction(self, link = None):\n",
    "        try:\n",
    "            self.zip_file = requests.get(self.link)\n",
    "            with open('zip_file.zip', 'wb') as f:\n",
    "                f.write(self.zip_file.content)\n",
    "            self.xml_file = ''\n",
    "            with zipfile.ZipFile('zip_file.zip', 'r') as f:\n",
    "                self.xml_file = f.namelist()[0]\n",
    "                f.extractall('')\n",
    "            if not self.xml_file:\n",
    "                raise Exception('Could not extract xml file from zip')\n",
    "            return self.xml_file\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in zip_extraction: {e}\")\n",
    "            raise e\n",
    "    \n",
    "            \n",
    "    def xml_to_csv(self, xml = None):\n",
    "        self.new = ET.parse(xml)   \n",
    "        self.test = self.new.getroot()\n",
    "        self.pattern = 'FinInstrmGnlAttrbts'   \n",
    "        self.children = ['Id', 'FullNm', 'ClssfctnTp', 'CmmdtyDerivInd', 'NtnlCcy'] \n",
    "        self.tag = 'Issr'\n",
    "        self.rows  = []\n",
    "        self.cols = [self.pattern + '.' + k for k in self.children]\n",
    "        self.cols.append(self.tag)\n",
    "        self.parent = 'TermntdRcrd'   \n",
    "        \n",
    "        for i in self.test.iter():         \n",
    "            if self.parent in i.tag:     \n",
    "                self.entry = [None for x in range(len(self.cols))]    \n",
    "                for child in i:\n",
    "                    if self.pattern in child.tag:  \n",
    "                            for c in child:     \n",
    "                                for k in range(len(self.children)):\n",
    "                                        if self.children[k] in c.tag:   \n",
    "                                            self.entry[k] = c.text\n",
    "                    if self.tag in child.tag:    \n",
    "                        self.entry[5] = child.text\n",
    "                self.rows.append(self.entry)   \n",
    "                \n",
    "        self.df = pd.DataFrame(self.rows, columns=self.cols)      \n",
    "        return self.df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    url = \"https://registers.esma.europa.eu/solr/esma_registers_firds_files/select?q=*&fq=publication_date:%5B2021-01-17T00:00:00Z+TO+2021-01-19T23:59:59Z%5D&wt=xml&indent=true&start=0&rows=100\" #Requirement-1: save the download link to url and download the xml file\n",
    "    p = Lambda(url)\n",
    "    zip_link = p.download_link()\n",
    "    xml_file = p.zip_extraction(zip_link)\n",
    "    df = p.xml_to_csv(xml_file)\n",
    "    df.to_csv('output.csv')\n",
    "    \n",
    "    #Store the csv from step 4) in an AWS S3 bucket\n",
    "    s3 = boto3.client(\"s3\", aws_access_key_id = \"AKIA57OPFLJQGYQWY5FX\", aws_secret_access_key=\"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\")\n",
    "    csv_buf = StringIO()\n",
    "    df.to_csv(csv_buf, header = True, index = False)\n",
    "    csv_buf.seek(0)\n",
    "    s3.put_object(Bucket=\"steeleye-aaa\", Body=csv_buf.getvalue(), Key='output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53003a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
